<!DOCTYPE html><html lang="en"><head><meta name="generator" content="React Static"/><title data-react-helmet="true">puigfp</title><meta charSet="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5, shrink-to-fit=no"/><link rel="preload" as="script" href="https://puigfp.github.io/templates/styles.75209627.js"/><link rel="preload" as="script" href="https://puigfp.github.io/templates/vendors~__react_static_root__/src/pages/blog/post.dbb0230d.js"/><link rel="preload" as="script" href="https://puigfp.github.io/templates/__react_static_root__/src/pages/blog/post.ff7d2ca5.js"/><link rel="preload" as="script" href="https://puigfp.github.io/templates/vendors~main.70b2b20c.js"/><link rel="preload" as="script" href="https://puigfp.github.io/main.b3bba2e8.js"/><link rel="preload" as="style" href="https://puigfp.github.io/styles.7ff28886.css"/><link rel="stylesheet" href="https://puigfp.github.io/styles.7ff28886.css"/><link data-react-helmet="true" href="https://puigfp.github.io/blog/atom.xml" type="application/atom+xml" rel="alternate" title="puigfp - all posts"/><link data-react-helmet="true" href="https://puigfp.github.io/blog/en/atom.xml" type="application/atom+xml" rel="alternate" title="puigfp - en"/><link data-react-helmet="true" href="https://puigfp.github.io/blog/fr/atom.xml" type="application/atom+xml" rel="alternate" title="puigfp - fr"/></head><body><div id="root"><div style="outline:none" tabindex="-1"><header><div class="site-title"><h1><a href="https://puigfp.github.io/">puigfp</a></h1><div class="quote">A compilation of the rabbit holes I fall into</div></div><nav><a href="https://github.com/puigfp">Github</a> / <a href="https://puigfp.github.io/">About</a><code>  // TODO</code></nav></header></div></div><script type="text/javascript">window.__routeInfo = JSON.parse("{\"template\":\"__react_static_root__/src/pages/blog/post.js\",\"sharedHashesByProp\":{},\"data\":{\"post\":{\"metadata\":{\"slug\":\"2020-01-03-kmp\",\"title\":\"The Knuth\u2013Morris\u2013Pratt algorithm\",\"date\":\"2020-01-03T00:00:00.000Z\",\"lang\":\"en\"},\"body\":\"\\nLet's say we want to search for a pattern `p` (a small string, the needle) inside a text `t` (a larger string, the haystack).\\n\\n## Naive algorithm\\n\\nA naive algorithm for this task could be:\\n\\n```python\\ndef naive_search(p, t):\\n    for i in range(0, len(t) - len(p) + 1):\\n        if t[i:i + len(p)] == p:\\n            return i\\n    return None\\n```\\n\\n_Implementation detail:_  \\nthe last check we want to do is `p == t[len(t) - len(p) : len(t)]`, that's why the range's upper bound is `len(t) - len(p) + 1`.\\n\\n### Complexity\\n\\nThe worst case time complexity of this algorithm is $O(|P|(|T|-|P|)) = O(|P||T|)$ where $|P|$ is the length of the pattern and $|T|$ the length of the text. This isn't practical for large inputs (eg. $P = 10^4$ and $T = 10^8$).\\n\\nHowever, this worst case time complexity doesn't happen for all possible inputs.\\n\\n### Example 1\\n\\nIf we search for `\\\"Morris\\\"` inside any larger text, we can see than most of time time, it takes only one comparison to know that `t[i:i+len(p)]` is different from `p`.\\n\\nLet's say it took 5 comparisons to know that `t[i:i+len(p)]` is different from `p`, then we know that `t[i:i+4]` is `p[:4]` (or `\\\"Morr\\\"`) and, in particular, we know that `t[i+1]` is different from `M` and thus it will take only one comparison to know that `t[i+1:i+1+len(p)]` is different from `p` (the same holds for `i+1`, `i+2` and `i+3`).\\n\\nThis is because the string we're looking for (`\\\"Morris\\\"`) doesn't have any repeating pattern and doesn't \\\"overlap itself\\\".\\n\\n### Example 2\\n\\nNow, let's look at a more pathological example.\\n\\nIf we search for `\\\"aaaab\\\"` inside `\\\"aaaaaaaaaaaaaabaaaa\\\"`, most of the time, it will take 5 comparisons to know that `t[i:i+len(p)]` is different from `p`.  \\nIf `t[i:i+len(p)] == p` returned false after 5 comparisons, we threw away the knowledge than `t[i:i+4]` is equal to `p[:4]`.\\nIf `t[i:i+4]` is equal to `p[:4]` (`\\\"aaaa\\\"`), we know that `t[i+1:i+4]` is equal to `p[1:4]` (`\\\"aaa\\\"`), which is itself equal to `p[:3]`. This knowledge can save us 3 comparisons when we test if `t[i+1:i+1+len(p)]` is equal to `p`.\\n\\nThe same idea holds for strings that have more complicated repeating patterns: for instance if it takes 10 comparisons to know that `t[i:i+10]` is different from `\\\"ababcababd\\\"`, we know that `t[i+5:i+9]` is equal to `p[5:9]` (`\\\"abab\\\"`), which is itself equal to `p[:4]`. This knowledge could save us 4 comparisons when when testing for `t[i+5:i+15] == p`.\\n\\nThis is the main idea behind the [Knuth\u2013Morris\u2013Pratt (or KMP) algorithm](https://en.wikipedia.org/wiki/Knuth%E2%80%93Morris%E2%80%93Pratt_algorithm).\\n\\n## The Knuth\u2013Morris\u2013Pratt algorithm\\n\\nLet's assume that we have an function called `kmp_jump_table(p)`, that, for any pattern `p`, returns a `jump` list of length `len(p)+1` with the following properties:\\n\\n- `jump[0] = -1`\\n- `jump[i]` is the largest `0 <= j < i` such as `p[:j] == p[i-j:i]` (ie. there exists `s` such as `p[:i] == s + p[:j]`)\\n\\nFor example, for `p = \\\"ababc\\\"`, we would have `jump = [-1, 0, 0, 1, 2, 0]`.\\n\\nThe beautiful property of this `jump` list is: for any `j > 0`, if `p[:j] == t[i-j:i]`, then `p[:jump[j]] == t[i-jump[j]:i]` (`jump[j] >= 0` because `j > 0`).\\n\\nHere's an implementation of the KMP algorithm:\\n\\n```python\\ndef kmp_search(p, t):\\n    jump = kmp_jump_table(p)\\n    j = 0\\n    for i in range(len(t)): # loop 1\\n        while j >= 0 and t[i] != p[j]: # loop 2\\n            j = jump[j]\\n        j += 1\\n        if j == len(p):\\n            return i + 1 - len(p)\\n    return None\\n```\\n\\nThe following invariants are maintained during the execution:\\n\\n- at the beginning of every iteration of loop 1:\\n\\n  - `j >= 0`\\n  - `j` is the greatest number such as `p[:j] == t[i-j:i]`\\n\\n- at the beginning of every iteration of loop 2:\\n  - `j` is any number such as `p[:j] == t[i-j:i]`\\n\\nThe magic happens in loop 2.\\n\\nBecause of how `jump` was constructed, `j = jump[j]` keeps the loop 2 invariant true.\\n\\nLoop 2 exits when either:\\n\\n- `j < 0` (ie. `j == -1`): we have explored all `j` values such as `p[:j] == t[i-j:i]`, and we didn't find any that verifies `t[i] == p[j]`\\n\\n- `t[i] == p[j]`: we have found a `j` value such as `p[:j] == t[i-j:i]` and `t[i] == p[j]`, and since we explored the `j` candidate values in a decreasing order (we have `jump[j] < j`), the `j` we found is the greatest\\n\\nIn both cases, `j` is the greatest number such as `p[:j+1] == t[i+1-(j+1):i+1]`, so performing `j += 1` after loop 2 exits makes sure that the loop 1 invariant is true at the beginning of the next iteration.\\n\\n_Note: the `jump[j] < j` condition also makes sure that loop 2 exits eventually_\\n\\nAfter performing `j += 1`, we have `p[:j] == t[i+1-j:i+1]`, we exit if `j == len(p)`, because we have `p[:j] == p` and thus the beginning of `p` in `t` is at index `i + 1 - len(p)`.\\n\\n## Examples\\n\\n_`p = \\\"aab\\\"` and `t = \\\"aacaaab\\\"`_\\n\\n```\\n- loop 1: i=0 j=0 p=[]aab t=[]aacaaab\\n  loop 1: p[j] == t[i] (a == a) => extend matched prefix\\n\\n- loop 1: i=1 j=1 p=[a]ab t=[a]acaaab\\n  loop 1: p[j] == t[i] (a == a) => extend matched prefix\\n\\n- loop 1: i=2 j=2 p=[aa]b t=[aa]caaab\\n    - loop 2: p[j] != t[i] (b != c) => try to extend smaller prefix\\n      loop 2: j = jump[2] = 1\\n      loop 2: i=2 j=1 p=[a]ab t=a[a]caaab\\n    - loop 2: p[j] != t[i] (a != c) => try to extend smaller prefix\\n      loop 2: j = jump[1] = 0\\n      loop 2: i=2 j=0 p=[]aab t=aa[]caaab\\n    - loop 2: p[j] != t[i] (a != c) => try to extend smaller prefix\\n      loop 2: j = jump[0] = -1\\n      loop 2: i=2 j=-1\\n  loop 1: cannot extend any prefix\\n\\n- loop 1: i=3 j=0 p=[]aab t=aac[]aaab\\n  loop 1: p[j] == t[i] (a == a) => extend matched prefix\\n\\n- loop 1: i=4 j=1 p=[a]ab t=aac[a]aab\\n  loop 1: p[j] == t[i] (a == a) => extend matched prefix\\n\\n- loop 1: i=5 j=2 p=[aa]b t=aac[aa]ab\\n    - loop 2: p[j] != t[i] (b != a) => try to extend smaller prefix\\n      loop 2: j = jump[2] = 1\\n      loop 2: i=5 j=1 p=[a]ab t=aaca[a]ab\\n  loop 1: p[j] == t[i] (a == a) => extend matched prefix\\n\\n- loop 1: i=6 j=2 p=[aa]b t=aaca[aa]b\\n  loop 1: p[j] == t[i] (b == b) => extend matched prefix\\n  loop 1: j == len(p) => return 4 = i + 1 - len(p)\\n```\\n\\n_`p = \\\"ababc\\\"` and `t = \\\"abababc\\\"`_\\n\\nNotice what happens on iteration `i = 4`.\\n\\n```\\n- loop 1: i=0 j=0 p=[]ababc t=[]abababc\\n  loop 1: p[j] == t[i] (a == a) => extend matched prefix\\n\\n- loop 1: i=1 j=1 p=[a]babc t=[a]bababc\\n  loop 1: p[j] == t[i] (b == b) => extend matched prefix\\n\\n- loop 1: i=2 j=2 p=[ab]abc t=[ab]ababc\\n  loop 1: p[j] == t[i] (a == a) => extend matched prefix\\n\\n- loop 1: i=3 j=3 p=[aba]bc t=[aba]babc\\n  loop 1: p[j] == t[i] (b == b) => extend matched prefix\\n\\n- loop 1: i=4 j=4 p=[abab]c t=[abab]abc\\n    - loop 2: p[j] != t[i] (c != a) => try to extend smaller prefix\\n      loop 2: j = jump[4] = 2\\n      loop 2: i=4 j=2 p=[ab]abc t=ab[ab]abc\\n  loop 1: p[j] == t[i] (a == a) => extend matched prefix\\n\\n- loop 1: i=5 j=3 p=[aba]bc t=ab[aba]bc\\n  loop 1: p[j] == t[i] (b == b) => extend matched prefix\\n\\n- loop 1: i=6 j=4 p=[abab]c t=ab[abab]c\\n  loop 1: p[j] == t[i] (c == c) => extend matched prefix\\n  loop 1: j == len(p) => return 2 = i + 1 - len(p)\\n```\\n\\n## Building the jump table\\n\\nPer the previous section, `kmp_jump_table(p)` should be a function that, for any pattern `p`, returns a `jump` list of length `len(p)+1` with the following properties:\\n\\n- `jump[0] = -1`\\n- `jump[i]` is the largest `0 <= j < i` such as `p[:j] == p[i-j:i]` (ie, there exists `s` such as `p[:i] == s + p[:j]`)\\n\\nHere's an implementation of the `kmp_jump_table` function:\\n\\n```python\\ndef kmp_jump_table(p):\\n    jump = [-1] + [0] * len(p)\\n    j = 0\\n    for i in range(2, len(p) + 1): # loop 1\\n        while j >= 0 and p[i - 1] != p[j]: # loop 2\\n            j = jump[j]\\n        j += 1\\n        jump[i] = j\\n    return jump\\n```\\n\\nThis code looks a lot like the KMP algorithm itself.\\n\\nThe following invariants are maintained during the execution:\\n\\n- at the beginning of every iteration of loop 1:\\n\\n  - `0 <= j < i - 1`\\n  - `j` is the greatest number such as `p[:j] == p[i-1-j:i-1]`\\n  - the final values for `jump[0],jump[1],...,jump[i-1]` are already computed\\n\\n- at the beginning of every iteration of loop 2:\\n  - `j` is any number such as `p[:j] == p[i-1-j:i-1]`\\n\\nLike in the KMP algorithm, `j = jump[j]` keeps the loop 2 invariant true.\\n\\nLoop 2 exits when either:\\n\\n- `j < 0` (ie. `j == -1`): we have explored all `j` values such as `p[:j] == t[i-1-j:i-1]` and we didn't find any that verifies `p[i-1] == p[j]`\\n\\n- `p[i-1] == p[j]`: we have found a `j` value such as `p[:j] == p[i-1-j:i-1]` and `p[i-1] == p[j]`, and since we explored the `j` candidate values in a decreasing order (because `jump[j] < j`), the `j` we found is the greatest\\n\\nIn both cases, `j` is the greatest number such as `p[:j+1] == p[i-(j+1):i]`, so performing `j += 1` after loop 2 exits makes sure that the loop 1 invariant is true at the beginning of the next iteration.\\n\\n## Complexity\\n\\nIn the main part of the KMP algorithm:\\n\\n- loop 1 runs at most `len(t)` times\\n- loop 2 runs at most `len(t)` times (in total)\\n  - the value of `j` has a lower bound: `-1`\\n  - each loop 2 iteration decreases the value of `j`: `j = jump[j]` ( `j < jump[j]`)\\n  - `j += 1` is run once per loop 1 iteration\\n  - thus, the total number of loop 2 iterations is smaller than the number of loop 1 iterations\\n\\nThe KMP algorithm itself has complexity $O(|T|)$.\\n\\nWith a similar reasoning, we can see that building the jump table has an $O(|P|)$ time complexity.\\n\\n**In conclusion, the KMP algorithm has an $O(|P| + |T|)$ time complexity.**\\n\\n## Benchmarks\\n\\n### vs. the naive algorithm\\n\\nLet's now do some benchmarks to check that KMP is faster than the naive algorithm.\\n\\nIn the following benchmarks, an input of size $L$ is composed of a text of length $L$ and a pattern of size $L/2$, both randomly generated and containing 3 different characters (`a`, `b` and `c`).\\n\\nBecause there are only 3 different characters, it's likely that the random patterns will overlap themselves.\\n\\n![](images/comparison_kmp_naive.png)\\n\\nWe can see that the KMP algorithm is a lot faster than the naive algorithm for large inputs !\\n\\nNow let's check that the time complexities are what we expect.\\n\\n![](./images/naive_order_2.png)\\n\\nWe can fit it almost perfectly with an order 2 polynomial, so this seems to confirm that the naive algorithm has an $O(|L|^2)$ time complexity.\\n\\n![](./images/kmp_linear.png)\\n\\nAnd this seems to show that the KMP algorithm has an $O(|L|)$ time complexity.\\n\\n### vs. `str.find`\\n\\nDoes this mean that this implementation of the KMP algorithm should actually be used ?\\n\\nThere is a method (`str.find`) in the Python standard library that does exactly the same thing, but calls a C function:\\n\\n```python\\ndef str_find_search(p, t):\\n    res = t.find(p)\\n    return res if res != -1 else None\\n```\\n\\nIt turns out that this code is 100 times faster than the above KMP implementation.\\n\\n![](images/comparison_kmp_str_find_log.png)\\n\\nIt's not that surprising. In Python, it's almost always better to use a library that calls native code under the hood than rolling your own implementation of an algorithm[^numba].\\n\\n[^numba]: But if you have to, using [PyPy](https://pypy.org/) or [numba](http://numba.pydata.org/) can make it run a lot faster.\\n\"}},\"path\":\"blog/post/2020-01-03-kmp\",\"sharedData\":{},\"siteData\":{}}");</script><script defer="" type="text/javascript" src="https://puigfp.github.io/templates/styles.75209627.js"></script><script defer="" type="text/javascript" src="https://puigfp.github.io/templates/vendors~__react_static_root__/src/pages/blog/post.dbb0230d.js"></script><script defer="" type="text/javascript" src="https://puigfp.github.io/templates/__react_static_root__/src/pages/blog/post.ff7d2ca5.js"></script><script defer="" type="text/javascript" src="https://puigfp.github.io/templates/vendors~main.70b2b20c.js"></script><script defer="" type="text/javascript" src="https://puigfp.github.io/main.b3bba2e8.js"></script></body></html>